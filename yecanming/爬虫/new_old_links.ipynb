{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 设置请求头部信息，模拟浏览器请求\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "# 设置YachtWorld网站上的搜索条件\n",
    "search_params = {\n",
    "    'class': 'sail',\n",
    "    # 'price': 'USD100000-500000',\n",
    "    # 'length': '40-50ft'\n",
    "}\n",
    "base_url = 'https://www.yachtworld.com'\n",
    "\n",
    "requests.get(base_url, \n",
    "    headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666/666 [01:37<00:00,  6.82it/s] \n"
     ]
    }
   ],
   "source": [
    "# 使用 Concurrent.futures 模块中的 ThreadPoolExecutor 类来实现异步请求\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "# pages = 1\n",
    "pages = 666\n",
    "req_list = list(range(pages))\n",
    "# sn = requests.Session()\n",
    "def transform(i):\n",
    "    # temp = sn.get(f'https://www.yachtworld.com/boats-for-sale/condition-new/type-sail/?page={i+1}', headers=headers).text\n",
    "    temp = requests.get(f'https://www.yachtworld.com/boats-for-sale/type-sail/?page={i+1}', headers=headers).text\n",
    "    # temp = requests.get(f'https://www.yachtworld.com/boats-for-sale/condition-used/type-sail/sort-recommended:desc/?page={i+1}', headers=headers).text\n",
    "    req_list[i] = BeautifulSoup(temp, 'html.parser')\n",
    "with ThreadPoolExecutor(max_workers=64) as t:\n",
    "    tasks = [t.submit(transform, i) for i in range(pages)]\n",
    "    for future in tqdm(as_completed(tasks), total=len(tasks)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soups = req_list\n",
    "all(map(lambda x: isinstance(x, BeautifulSoup), soups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     links \u001b[39m=\u001b[39m [link\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m link  \u001b[39min\u001b[39;00m a\u001b[39m.\u001b[39mfind_all(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m links\n\u001b[0;32m----> 9\u001b[0m links \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m(\u001b[39mmap\u001b[39;49m(get_urls_from_search_page, soups), [])\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mget_urls_from_search_page\u001b[0;34m(soup)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_urls_from_search_page\u001b[39m(soup:List[BeautifulSoup]):\n\u001b[1;32m      4\u001b[0m     a \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39m#root > div.search > div.flex.flex-row > div.search-right-col > div.pagination-and-results-container.search-display > div.listings-container\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     a \u001b[39m=\u001b[39m a[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m      6\u001b[0m     links \u001b[39m=\u001b[39m [link\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m link  \u001b[39min\u001b[39;00m a\u001b[39m.\u001b[39mfind_all(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m links\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_urls_from_search_page(soup:List[BeautifulSoup]):\n",
    "    a = soup.select('#root > div.search > div.flex.flex-row > div.search-right-col > div.pagination-and-results-container.search-display > div.listings-container')\n",
    "    a = a[0]\n",
    "    links = [link.get('href') for link  in a.find_all(name='a')]\n",
    "    return links\n",
    "\n",
    "links = sum(map(get_urls_from_search_page, soups), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(map(lambda x: x.startswith('https://'), links)) # 合法性\n",
    "len(links) # 数量\n",
    "# unique的数量\n",
    "len(set(links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('old_links.txt', 'w') as f:\n",
    "    f.write('\\n'.join(links))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
